{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a62698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\Runs_llm_locally\\huggingface\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ca777",
   "metadata": {},
   "source": [
    "### **Load our environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68159cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "access_token = os.getenv(\"HUGGINGFACEHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d69a8",
   "metadata": {},
   "source": [
    "### **Define our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daec679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53044c7",
   "metadata": {},
   "source": [
    "## **Download our given model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df749540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.16s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token= access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token= access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b5a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(f\"tokenizer/{model_name}\")\n",
    "model.save_pretrained(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e788fa83",
   "metadata": {},
   "source": [
    "### **Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4648a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 16.13it/s]\n"
     ]
    }
   ],
   "source": [
    "load_tokenizer = AutoTokenizer.from_pretrained(f\"tokenizer/{model_name}\")\n",
    "load_model = AutoModelForCausalLM.from_pretrained(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5e9a1",
   "metadata": {},
   "source": [
    "### Test how it will response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360d4b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.46it/s]\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"I am an artificial intelligence model designed to assist and provide information to users. I am a highly advanced language model, trained on a massive dataset of text from various sources, including books, articles, research papers, and websites.\\n\\nMy primary function is to understand and respond to natural language queries, providing accurate and relevant information on a wide range of topics. I can answer questions, generate text, summarize content, and even engage in conversation.\\n\\nI am constantly learning and improving my knowledge base, so the more I interact with users like you, the more accurate and up-to-date my information becomes. I am here to help with any questions or topics you'd like to discuss, so feel free to ask me anything!\\n\\nSome of my capabilities include:\\n\\n* Answering questions on various subjects, including history, science, technology, literature, and more\\n* Generating text on a given topic or subject\\n* Summarizing long pieces of text into concise summaries\\n* Translating text from one language to another\\n* Providing definitions and explanations of words and phrases\\n* Engaging in conversation and responding to follow-up questions\\n* Offering suggestions and ideas on a wide range of topics\\n\\nI am always happy to help, so what's on your mind?\"}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    #torch_dtype=torch.bfloat16,\n",
    "    #device_map=\"auto\",\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who is vastly knowledgeable AI model knows everything!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b3d11",
   "metadata": {},
   "source": [
    "### **Test how it respond**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74827de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is Deep Learning? Give me 5 points on it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2120e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_embeddings = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bfe0737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,   3923,    374,  18682,  21579,     30,  21335,    757,    220,\n",
       "             20,   3585,    389,    433]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae3d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = model.generate(**prompt_embeddings, max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99444fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,   3923,    374,  18682,  21579,     30,  21335,    757,    220,\n",
       "             20,   3585,    389,    433,    198,   8586,    527,    220,     20,\n",
       "           1401,   3585,    922,  18682,  21579,   1473,     16,     13,    220,\n",
       "           3146,   9470,  16895,  61577,  39810,    320,  12272,     82,  33395,\n",
       "             25,  18682,  21579,    374,    264,  27084,    315,  13257,  21579,\n",
       "            430,   5829,  59294,  61577,  39810,    320,  12272,     82,      8,\n",
       "            311,  24564,    323,  14532,    828,     13,   2147,  48460,    527,\n",
       "          14948,    555,    279,   3823,   8271,    596,  30828,   6070,    323,\n",
       "            734,     11,    323,    527,  24306,    315,  13931,    315,  83416,\n",
       "           7954,    320,    818,  54769,      8,    430,   1920,    323,  30382,\n",
       "           2038,    382,     17,     13,    220,   3146,  20981,   8288,   1155,\n",
       "           3700,    346,  95810,    320,   2735,     47,  33395,     25,  18682,\n",
       "          21579,   4211,  11383,   6824,    315,    264,  17896,   8288,   1155,\n",
       "           3700,    346,  95810,    320,   2735,     47,      8,  18112,     11,\n",
       "            902,   5764,   5361,  13931,    315,   7954,    430,   1920,    323,\n",
       "           5276,    279,   1988,    828,     13,   9062,   6324,  47310,    311,\n",
       "           4097,    279,    828,    304,    264,    810,   8278,    323,   6485,\n",
       "           1648,     11,  10923,    279,   1646,    311,  12602,   5190,  11852,\n",
       "          12912,    323,  12135,    382,     18,     13,    220,   3146,  38030,\n",
       "            323,  58839,  96618,  18682,  21579,   4211,   1397,   3544,  15055,\n",
       "            315,   4967,    828,    323,  55580,   5070,    311,   4048,    323,\n",
       "          30536,    872,   5137,     13,   1115,    374,  17427,   1555,    264,\n",
       "           1920,   2663,   1203,   2741,  28236,     11,    902,  18065,  17425,\n",
       "           1113,   6103,  29512,   1555,    279,   4009,    311,   7652,    279,\n",
       "          14661,    323,  50183,    315,   1855,   2494,    382,     19,     13,\n",
       "            220,   3146,  51459,  96618,  18682,  21579,    706,  12387,   8522,\n",
       "            304,   5789,   1778,    439,   6500,  11376,     11,   5933,   4221,\n",
       "           8863,     11,   8982,  18324,     11,    323,  74706,     13,   1102,\n",
       "            649,    387,   1511,    369,   9256,   1778,    439,   2217,  24790,\n",
       "             11,   1665,  18468,     11,  27065,   6492,     11,    323,   1495,\n",
       "           9659,    382,     20,     13,    220,   3146,   1163,  43470,    323,\n",
       "          29108,    811,  96618,  18185,   1202,   1690,  48188,     11,  18682,\n",
       "          21579,   1101,  12580,   3892,  11774,    323,   9669,     11,   2737,\n",
       "            279,   1205,    369,   3544,  15055,    315,    828,     11,    279,\n",
       "          23965,    315,    279,   4211,     11,    323,    279,   5326,    315,\n",
       "            927,   6410,   1303,     13,  23212,     11,  18682,  21579,   4211,\n",
       "            649,    387,   5107,    311,  14532,    323,   3619,     11,    902,\n",
       "            649,   1304,    433,  17436,    311,   7095,    872,  16674,     13,\n",
       "         128009]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda668d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>What is Deep Learning? Give me 5 points on it\n",
      "Here are 5 key points about Deep Learning:\n",
      "\n",
      "1.  **Artificial Neural Networks (ANNs)**: Deep Learning is a subset of Machine Learning that uses Artificial Neural Networks (ANNs) to analyze and interpret data. ANNs are inspired by the human brain's neural structure and function, and are composed of layers of interconnected nodes (neurons) that process and transmit information.\n",
      "\n",
      "2.  **Multi-Layer Perceptron (MLP)**: Deep Learning models typically consist of a Multi-Layer Perceptron (MLP) architecture, which includes multiple layers of nodes that process and transform the input data. Each layer learns to represent the data in a more abstract and complex way, allowing the model to capture higher-level patterns and relationships.\n",
      "\n",
      "3.  **Training and Optimization**: Deep Learning models require large amounts of training data and computational resources to learn and optimize their parameters. This is achieved through a process called backpropagation, which involves propagating errors backwards through the network to adjust the weights and biases of each node.\n",
      "\n",
      "4.  **Applications**: Deep Learning has numerous applications in areas such as computer vision, natural language processing, speech recognition, and robotics. It can be used for tasks such as image classification, object detection, sentiment analysis, and text generation.\n",
      "\n",
      "5.  **Challenges and Limitations**: Despite its many successes, Deep Learning also faces several challenges and limitations, including the need for large amounts of data, the complexity of the models, and the risk of overfitting. Additionally, Deep Learning models can be difficult to interpret and understand, which can make it challenging to trust their outputs.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(response[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

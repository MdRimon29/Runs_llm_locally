{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "374a58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "### Load api key \n",
    "load_dotenv()\n",
    "HUGGINGFACEHUB_API_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "### define llm model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=1024,\n",
    "    huggingfacehub_api_token= HUGGINGFACEHUB_API_KEY\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13704994",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select an embeddings model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42142e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define vector store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b2b68",
   "metadata": {},
   "source": [
    "### **Loading documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41f5abf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"data/attention-is-all-you-need.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e331b554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brai\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7961d",
   "metadata": {},
   "source": [
    "### **Splitting documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3710b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73b74fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffbac31",
   "metadata": {},
   "source": [
    "### **Storing documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d94cd3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['52e81fa8-60f6-479c-9964-47015effc93f', 'f4ff3249-a44d-486b-af2c-a878d6bff025', '64ace985-8974-4258-9820-2573f30554d9']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7031436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**What is Python?**\\n\\nPython is a high-level, interpreted programming language that is widely used for various purposes such as web development, scientific computing, data analysis, artificial intelligence, and more. It was created in the late 1980s by Guido van Rossum and is now maintained by the Python Software Foundation.\\n\\n**Key Features of Python:**\\n\\n1.  **Easy to Learn:** Python has a simple syntax and is relatively easy to learn, making it a great language for beginners.\\n2.  **High-Level Language:** Python is a high-level language, meaning it abstracts away many low-level details, allowing developers to focus on the logic of the program without worrying about the underlying implementation.\\n3.  **Interpreted Language:** Python code is interpreted at runtime, which means that the code is not compiled before it is executed. This makes it easier to write and test code quickly.\\n4.  **Object-Oriented:** Python is an object-oriented language, which means it supports the concept of objects and classes. This makes it easy to organize and structure code.\\n5.  **Large Standard Library:** Python has a vast collection of libraries and frameworks that make it easy to perform various tasks, such as data analysis, web development, and more.\\n\\n**Use Cases for Python:**\\n\\n1.  **Web Development:** Python is widely used for web development, with popular frameworks like Django and Flask.\\n2.  **Data Analysis and Science:** Python is a popular choice for data analysis and science, with libraries like NumPy, pandas, and scikit-learn.\\n3.  **Artificial Intelligence and Machine Learning:** Python is widely used for AI and ML tasks, with libraries like TensorFlow and Keras.\\n4.  **Automation:** Python is often used for automating tasks, such as data entry, file management, and more.\\n\\n**Why Choose Python?**\\n\\n1.  **Easy to Learn:** Python has a low barrier to entry, making it a great language for beginners.\\n2.  **High Productivity:** Python allows developers to write code quickly and efficiently, thanks to its syntax and libraries.\\n3.  **Cross-Platform:** Python can run on multiple platforms, including Windows, macOS, and Linux.\\n4.  **Large Community:** Python has a large and active community, with many resources available for learning and troubleshooting.\\n\\nIn summary, Python is a versatile and powerful language that is widely used for various purposes. Its ease of use, high productivity, and large community make it a great choice for developers of all levels.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 518, 'prompt_tokens': 39, 'total_tokens': 557}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b2baa-1acf-7231-88bc-ae14155d32c8-0' usage_metadata={'input_tokens': 39, 'output_tokens': 518, 'total_tokens': 557}\n"
     ]
    }
   ],
   "source": [
    "response= model.invoke(\"What is Python?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b38fc5",
   "metadata": {},
   "source": [
    "### **RAG QNA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23375123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_classic.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6387fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",  # or \"mmr\"\n",
    "    search_kwargs={\"k\": 3}     # number of docs to retrieve per query\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94dc620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following context to answer the question.\n",
    "If the answer is not contained in the context, respond as \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f3380ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,           # your ChatHuggingFace instance\n",
    "    chain_type=\"stuff\",  # \"stuff\", \"map_reduce\", \"refine\"\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}  # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35383052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer model architecture is described as a fully connected feed-forward network. It consists of a stack of identical layers, which includes two sub-layers in each encoder layer and three sub-layers in each decoder layer. \n",
      "\n",
      "In the encoder layer, the two sub-layers are connected with residual connections, followed by layer normalization. The output of each sub-layer is calculated as LayerNorm(x+ Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself.\n",
      "\n",
      "In the decoder layer, a third sub-layer is added, which performs multi-head attention over the output of the encoder stack. The decoder layers also employ residual connections and layer normalization, with the self-attention sub-layer modified to prevent positions from attending to subsequent positions.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the model architecture in given context?\"\n",
    "answer = qa_chain.run(question)\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf7a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "access_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73ec85",
   "metadata": {},
   "source": [
    "### **Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee76cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"data/attention-is-all-you-need.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258000f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brai\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cee9b6",
   "metadata": {},
   "source": [
    "### **Splitting Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0f53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a565f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec184f25",
   "metadata": {},
   "source": [
    "### **Store in a vector database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d58569",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select an embeddings model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30dbe0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define vector store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8eff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00408df4-23ee-4ff0-af03-0306314be719', 'cfb8639b-3231-425d-a97b-1f09db3baf16', '6d842f06-36da-4c5d-ac78-32346e96e579']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c4927",
   "metadata": {},
   "source": [
    "### **Download our model Locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee274824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "#model_name=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "#model_name=\"microsoft/Phi-3-mini-4k-instruct\"  # too much time it takes to response\n",
    "#model_name = \"openai-community/gpt2\"   # Give error\n",
    "model_name = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93091504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(f\"tokenizer/{model_name}\")\n",
    "model.save_pretrained(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4994bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Qwen, an Alibaba Cloud developed model designed to assist with answering questions and providing information on a wide range of topics.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75f3bd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727d0b3",
   "metadata": {},
   "source": [
    "### **Create a RAG pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "254ef473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_classic.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0110a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",  # or \"similarity\"\n",
    "    search_kwargs={\"k\": 3}     # number of docs to retrieve per query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9cbf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9df0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,           \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef37a2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "    Question: What is the main contribution of this paper? \n",
      "    Context: 2017.\n",
      "[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\n",
      "In International Conference on Learning Representations, 2017.\n",
      "[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n",
      "[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\n",
      "arXiv:1703.10722, 2017.\n",
      "[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\n",
      "Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\n",
      "arXiv:1703.03130, 2017.\n",
      "[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\n",
      "Information Processing Systems, (NIPS), 2016.\n",
      "10\n",
      "\n",
      "we found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned\n",
      "linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\n",
      "queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "output values. These are concatenated and once again projected, resulting in the ﬁnal values, as\n",
      "depicted in Figure 2.\n",
      "Multi-head attention allows the model to jointly attend to information from different representation\n",
      "subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "4To illustrate why the dot products get large, assume that the components of q and k are independent random\n",
      "variables with mean 0 and variance 1. Then their dot product, q · k = ∑dk\n",
      "i=1 qiki, has mean 0 and variance dk.\n",
      "4\n",
      "\n",
      "tensorflow/tensor2tensor.\n",
      "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\n",
      "comments, corrections and inspiration.\n",
      "9 \n",
      "    Answer:\n",
      "     The main contribution of this paper is the use of structured attention networks to improve the performance of recurrent neural networks by leveraging the shared representations of different subspaces.\n",
      "This answer is concise and directly addresses the question asked, while providing a detailed explanation of the paper's contributions. It maintains the core information while being clear and concise.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the main contribution of this paper?\"\n",
    "answer = qa_chain.run(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
